{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5da09f",
   "metadata": {},
   "source": [
    "# 1 Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1e746",
   "metadata": {},
   "source": [
    "Language Detection using the European Parliament Proceedings Parallel Corpus. European Parliament Proceedings Parallel Corpus is a text dataset used for evaluating language detection engines. The 1.5GB corpus includes 21 languages spoken in EU. This project aims to build a machine learning model trained on this dataset to predict new unseen data.\n",
    "\n",
    "The Training data can be downloaded [here](https://www.statmt.org/europarl/#:~:text=starting%20with%20%22%3C%22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a79295ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10e58e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas packages\n",
    "import pandas as pd\n",
    "def readData(language):\n",
    "    data_language = pd.read_csv(\"data\\\\\"+language+\".txt\", sep=\"\\r\")\n",
    "    data_language['language']=language\n",
    "    #pick 20 000 rows rendom for every language\n",
    "    return data_language.sample(n=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e64ee3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_english=readData(\"english\")\n",
    "data_spanish=readData(\"spanish\")\n",
    "data_french=readData(\"french\")\n",
    "data_italian=readData(\"italian\")\n",
    "data_german=readData(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a234e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dietro a questo \"nuovo governo\" , mi sembra si...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We would also draw attention to the human side...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Señor Presidente, ayer oímos mucho a los orado...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Me estoy refiriendo a la continua tragedia de ...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Este Comité Militar, como pueden ustedes imagi...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fra l'altro, non ci lasciano indifferenti talu...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Darum unterstütze ich, dass es jetzt endlich e...</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nous espérons que l' on attribuera aux points ...</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dado que su autor no está presente, la pregunt...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The EU organs and institutions can exercise fa...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence language\n",
       "0  Dietro a questo \"nuovo governo\" , mi sembra si...  italian\n",
       "1  We would also draw attention to the human side...  english\n",
       "2  Señor Presidente, ayer oímos mucho a los orado...  spanish\n",
       "3  Me estoy refiriendo a la continua tragedia de ...  spanish\n",
       "4  Este Comité Militar, como pueden ustedes imagi...  spanish\n",
       "5  Fra l'altro, non ci lasciano indifferenti talu...  italian\n",
       "6  Darum unterstütze ich, dass es jetzt endlich e...   german\n",
       "7  Nous espérons que l' on attribuera aux points ...   french\n",
       "8  Dado que su autor no está presente, la pregunt...  spanish\n",
       "9  The EU organs and institutions can exercise fa...  english"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat all the languages into one dataframe\n",
    "data = pd.concat([data_english,data_spanish,data_french,data_italian,data_german],ignore_index=True)\n",
    "#shuffle the data and reset the idex\n",
    "data = data.sample(frac=1,random_state=5).reset_index(drop=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff418d",
   "metadata": {},
   "source": [
    "# 2 Data pre-processing\n",
    "Removing noise from data : \n",
    "- remove punctuations : [!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]\n",
    "- remove digits \n",
    "- remove uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f720efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dietro a questo  nuovo governo    mi sembra si...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we would also draw attention to the human side...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>señor presidente  ayer oímos mucho a los orado...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me estoy refiriendo a la continua tragedia de ...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>este comité militar  como pueden ustedes imagi...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fra l altro  non ci lasciano indifferenti talu...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>darum unterstütze ich  dass es jetzt endlich e...</td>\n",
       "      <td>german</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nous espérons que l  on attribuera aux points ...</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dado que su autor no está presente  la pregunt...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the eu organs and institutions can exercise fa...</td>\n",
       "      <td>english</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence language\n",
       "0  dietro a questo  nuovo governo    mi sembra si...  italian\n",
       "1  we would also draw attention to the human side...  english\n",
       "2  señor presidente  ayer oímos mucho a los orado...  spanish\n",
       "3  me estoy refiriendo a la continua tragedia de ...  spanish\n",
       "4  este comité militar  como pueden ustedes imagi...  spanish\n",
       "5  fra l altro  non ci lasciano indifferenti talu...  italian\n",
       "6  darum unterstütze ich  dass es jetzt endlich e...   german\n",
       "7  nous espérons que l  on attribuera aux points ...   french\n",
       "8  dado que su autor no está presente  la pregunt...  spanish\n",
       "9  the eu organs and institutions can exercise fa...  english"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeNoise(data):\n",
    "    data[\"sentence\"]=data[\"sentence\"].str.replace('[0-9]', ' ',regex=True)\n",
    "    data[\"sentence\"]=data[\"sentence\"].str.replace('['+string.punctuation+']', ' ',regex=True)\n",
    "    data[\"sentence\"]=data[\"sentence\"].str.lower()\n",
    "    return data\n",
    "removeNoise(data.head(10).copy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ecb64c",
   "metadata": {},
   "source": [
    "# 3 splitting Data into Train and Test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83339161",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y =data[\"sentence\"],data[\"language\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db4fa3",
   "metadata": {},
   "source": [
    "# 4 Vetorizer (ID TF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a3d4986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),analyzer='word')\n",
    "model= Pipeline([('vectorizer',vectorizer),('clf',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281a79cc",
   "metadata": {},
   "source": [
    "# 4 Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dad4aa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce8d78",
   "metadata": {},
   "source": [
    "# 5 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bed05910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted= model.predict(X_test)\n",
    "accuracyScore = metrics.accuracy_score(y_test,y_predicted)\n",
    "accurac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2932813e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[389,   0,   1,   0,   0],\n",
       "       [  0, 408,   0,   2,   0],\n",
       "       [  0,   0, 385,   0,   0],\n",
       "       [  0,   0,   0, 394,   0],\n",
       "       [  0,   0,   0,   5, 416]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = metrics.confusion_matrix(y_test,y_predicted)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a462920",
   "metadata": {},
   "source": [
    "# 6 SAVE and LOAD the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bea8a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "saveModel = open('myModel.pckl','wb')\n",
    "pickle.dump(model,saveModel)\n",
    "saveModel.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba11af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import string\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    #load saved model\n",
    "    saveModel =open('myModel.pckl','rb')\n",
    "    model = pickle.load(saveModel)\n",
    "    saveModel.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4a545",
   "metadata": {},
   "source": [
    "# 7 Graphical interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c941729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "\n",
    "\n",
    "def languageDetector(inputText):\n",
    "    import string\n",
    "    import pickle\n",
    "    global model\n",
    "    global resultatFrame\n",
    "    #load saved model\n",
    "    saveModel =open('myModel.pckl','rb')\n",
    "    model = pickle.load(saveModel)\n",
    "    saveModel.close()\n",
    "    \n",
    "    #remove noise\n",
    "    inputText =inputText.replace('[0-9]', ' ')\n",
    "    inputText=inputText.replace('['+string.punctuation+']', ' ')\n",
    "    inputText=inputText.lower()\n",
    "    \n",
    "    #predection\n",
    "    predectedLanguage = model.predict([inputText])\n",
    "    probability = model.predict_proba([inputText])\n",
    "    allProb= pd.DataFrame(probability, columns=model.classes_)\n",
    "    \n",
    "    #dispaly resultat\n",
    "    \n",
    "    for child in resultatFrame.winfo_children():\n",
    "        child.destroy()\n",
    "\n",
    "    \n",
    "    predResult_label = tk.Label(resultatFrame,fg=\"#12183d\",bg='#f5f5f5',font=(\"Arial\", 15),\n",
    "                           padx=50,pady=50,\n",
    "                           text=\"this text is written in \"+predectedLanguage)\n",
    "    predResult_label[\"text\"] = \"Total tries: 0\"\n",
    "    predResult_label.pack()\n",
    "\n",
    "    resultatFrame.pack()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#windows\n",
    "app = tk.Tk()\n",
    "app.title(\"Language Detector\")\n",
    "app.minsize(1020, 700)\n",
    "width_value = app.winfo_screenwidth()\n",
    "height_value = app.winfo_screenheight()\n",
    "app.geometry(str(width_value) + \"x\" + str(height_value))\n",
    "app.configure(bg='#f5f5f5')\n",
    "\n",
    "\n",
    "#frames\n",
    "middleFrame = tk.Frame(app, background='#f5f5f5', width=700, height=height_value)\n",
    "\n",
    "title_label = tk.Label(middleFrame,fg=\"#12183d\",bg='#f5f5f5',font=(\"Arial\", 15),padx=50,pady=50, text=\"Welcome to our Language Detector \\n Our model support 5 languages (en,es,fr,it,de)\")\n",
    "title_label.pack()\n",
    "\n",
    "# Create text widget and specify size.\n",
    "textArea = tk.Text(middleFrame, height = 10, width = 70)\n",
    "textArea.pack()\n",
    "\n",
    "# Create button for detect text.\n",
    "btnDetect = tk.Button(middleFrame, text = \"Detect\",bg=\"#6378ff\",fg=\"white\",font=(\"Arial\", 15),pady=5,width = 50 ,command= lambda: languageDetector(textArea.get(\"1.0\",'end-1c')))\n",
    "btnDetect.pack(pady=10)\n",
    "#resultat frame\n",
    "resultatFrame =tk.Frame(middleFrame)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "middleFrame.pack()\n",
    "\n",
    "\n",
    "app.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e492802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "      <th>german</th>\n",
       "      <th>italian</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06714</td>\n",
       "      <td>0.187097</td>\n",
       "      <td>0.08356</td>\n",
       "      <td>0.590676</td>\n",
       "      <td>0.071527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   english    french   german   italian   spanish\n",
       "0  0.06714  0.187097  0.08356  0.590676  0.071527"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba=model.predict_proba([\"il va dormir\"])\n",
    "pd.DataFrame(proba, columns=model.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
